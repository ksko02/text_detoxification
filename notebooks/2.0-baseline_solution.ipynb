{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c922e4",
   "metadata": {},
   "source": [
    "# Baseline solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c31a74",
   "metadata": {},
   "source": [
    "This notebook presents the most elementary solution to the problem. The solution is to simply remove toxic words from the sentence without replacing them with anything and without paying attention to the context.  The solution is presented as an algorithm that relies on a ready-made list of toxic words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27247e",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc3686",
   "metadata": {},
   "source": [
    "#### 1. Load the whole dataset, because this algorithm does not need train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcba2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/interim/dataset.csv')\n",
    "\n",
    "X = df['source'].to_list()\n",
    "y = df['target'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b000791",
   "metadata": {},
   "source": [
    "#### 2. Load a list of toxic words that was compiled in 1.0-initial_data_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585e173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/interim/toxic_word.txt', \"r\") as f:\n",
    "    toxic_words_line = f.readlines()\n",
    "\n",
    "    \n",
    "my_toxic_words = list(set(toxic_words_line[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a5e1d4",
   "metadata": {},
   "source": [
    "#### 3. Load a list of toxic words that was found on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f65259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_toxic_words = []\n",
    "\n",
    "with open('../data/external/profanity_words_en.txt', \"r\") as f:\n",
    "    for word in f.readlines():\n",
    "        external_toxic_words.append(word[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afa5d2",
   "metadata": {},
   "source": [
    "## Base algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f15c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def baseline_detoxic_text(X, toxic_words):\n",
    "    # Define a set of punctuation characters\n",
    "    p = '.,?!'\n",
    "    \n",
    "    # Create a tokenizer that preserves words and some punctuation\n",
    "    tokenizer = RegexpTokenizer(r\"\\b\\w+\\b|[.,!?'\\\"]\")\n",
    "    \n",
    "    detox_sentences = []\n",
    "    \n",
    "    for sentence in X:\n",
    "        \n",
    "        # Tokenize the sentence into words\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        \n",
    "        result_sentence = []\n",
    "        \n",
    "        flag = False\n",
    "        \n",
    "        for word in words: \n",
    "            \n",
    "            # Check if the flag is set (toxic word encountered)\n",
    "            if flag:\n",
    "                # If the current word is not punctuation, add it to the result\n",
    "                if word not in p:\n",
    "                    result_sentence.append(word)\n",
    "                flag = False\n",
    "                \n",
    "            # Check if the word is not in the list of toxic words    \n",
    "            elif word.lower() not in toxic_words:\n",
    "                result_sentence.append(word)\n",
    "            else:\n",
    "                # Set the flag to handle toxic words\n",
    "                flag = True\n",
    "        \n",
    "        result_sentence = ' '.join(result_sentence)\n",
    "\n",
    "        # Correctly handle contractions like \"It's\"\n",
    "        result_sentence = re.sub(r\"(\\w+) ' (\\w+)\", r\"\\1'\\2\", result_sentence)\n",
    "\n",
    "        # Remove spaces before punctuation\n",
    "        result_sentence = re.sub(r\" ([.,!?])\", r\"\\1\", result_sentence)\n",
    "        \n",
    "        detox_sentences.append(result_sentence)\n",
    "        \n",
    "    return detox_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f89fe",
   "metadata": {},
   "source": [
    "### Functions for comparing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe3bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_comparison(X, output):\n",
    "    same = 0\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        # Check if the output sentence differs from the original\n",
    "        if X[i] != output[i]:\n",
    "            if len(X[i]) <= 50:\n",
    "                print(f'{i + 1}. Before the algorithm: {X[i]}\\nAfter the algorithm: {output[i]}')\n",
    "        else:\n",
    "            # Count identical sentences\n",
    "            same += 1\n",
    "\n",
    "    print('Number of identical sentences:', same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f512d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similar(sentence1, sentence2):\n",
    "    \n",
    "    # Create a CountVectorizer to convert sentences into a bag of words representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    sentences = [sentence1, sentence2]\n",
    "    v = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Calculate cosine similarity between the sentences\n",
    "    cosine_similarities = cosine_similarity(v)\n",
    "    \n",
    "    return cosine_similarities[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73dd25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_with_cosine(X, output):\n",
    "    result = []\n",
    "    same = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        # Calculate the cosine similarity between the original and modified sentences\n",
    "        cs = cosine_similar(X[i], output[i])\n",
    "        \n",
    "        if cs >= 0.99:\n",
    "            # Count identical sentences\n",
    "            same += 1\n",
    "            \n",
    "        if cs <= 0.9:\n",
    "            # Print the index, original, and modified sentences for low cosine similarity\n",
    "            print(f'{i + 1}. Before the algorithm: {X[i]}\\nAfter the algorithm: {output[i]}')\n",
    "            \n",
    "    print('Number of identical sentences:', same)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164471d",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4db78",
   "metadata": {},
   "source": [
    "#### 1. Running the algorithm with a self-compiled list of toxic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f235dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = baseline_detoxic_text(X, my_toxic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622e1770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Before the algorithm: I have orders to kill her.\n",
      "After the algorithm: I have orders to her.\n",
      "10. Before the algorithm: Real life starts the first time you fuck, kid.\n",
      "After the algorithm: Real life starts the first time you kid.\n",
      "13. Before the algorithm: Shit, this one I can't even pronounce.\n",
      "After the algorithm: this one I can't even pronounce.\n",
      "15. Before the algorithm: Hey, leave the poor bastard alone!\n",
      "After the algorithm: Hey, leave the poor alone!\n",
      "21. Before the algorithm: It told you this was a waste of my fucking time.\n",
      "After the algorithm: It told you this was a waste of my time.\n",
      "24. Before the algorithm: 'Shut up, you two, 'said Granny.\n",
      "After the algorithm: ' up, you two, ' said Granny.\n",
      "26. Before the algorithm: Does anal...\n",
      "After the algorithm: Does..\n",
      "32. Before the algorithm: I don't have to do shit.\n",
      "After the algorithm: I don't have to do\n",
      "33. Before the algorithm: God damn, this is gonna be a long night.\n",
      "After the algorithm: God this is gonna be a long night.\n",
      "39. Before the algorithm: what the fuck was that all about?\n",
      "After the algorithm: what the was that all about?\n",
      "40. Before the algorithm: Fuck! Get out of the fucking way!\n",
      "After the algorithm: Get out of the way!\n",
      "41. Before the algorithm: Trying to kill Ethan.\n",
      "After the algorithm: Trying to Ethan.\n",
      "42. Before the algorithm: \"Thanks, ass hole,\" Case said.\n",
      "After the algorithm: \" Thanks, hole, \" Case said.\n",
      "44. Before the algorithm: Really fucking annoying.\n",
      "After the algorithm: Really annoying.\n",
      "Number of identical sentences: 21\n"
     ]
    }
   ],
   "source": [
    "basic_comparison(X[:50], output_1[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c493c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Before the algorithm: I have orders to kill her.\n",
      "After the algorithm: I have orders to her.\n",
      "26. Before the algorithm: Does anal...\n",
      "After the algorithm: Does..\n",
      "32. Before the algorithm: I don't have to do shit.\n",
      "After the algorithm: I don't have to do\n",
      "40. Before the algorithm: Fuck! Get out of the fucking way!\n",
      "After the algorithm: Get out of the way!\n",
      "41. Before the algorithm: Trying to kill Ethan.\n",
      "After the algorithm: Trying to Ethan.\n",
      "42. Before the algorithm: \"Thanks, ass hole,\" Case said.\n",
      "After the algorithm: \" Thanks, hole, \" Case said.\n",
      "44. Before the algorithm: Really fucking annoying.\n",
      "After the algorithm: Really annoying.\n",
      "Number of identical sentences: 25\n"
     ]
    }
   ],
   "source": [
    "comparison_with_cosine(X[:50], output_1[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7da04e",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23fd98",
   "metadata": {},
   "source": [
    "Looking at the results, we can conclude that the algorithm does not change almost half of the sentences considered, as it does not look at the context of the sentence. Also the problem could be the list of toxic words, in order to make an unbiased evaluation, a solution with a different list was proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fb19f",
   "metadata": {},
   "source": [
    "#### 2. Running the algorithm with a ready-made list of toxic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c0a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_2 = baseline_detoxic_text(X, external_toxic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99623537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Before the algorithm: I have orders to kill her.\n",
      "After the algorithm: I have orders to her.\n",
      "10. Before the algorithm: Real life starts the first time you fuck, kid.\n",
      "After the algorithm: Real life starts the first time you kid.\n",
      "13. Before the algorithm: Shit, this one I can't even pronounce.\n",
      "After the algorithm: this one I can't even pronounce.\n",
      "15. Before the algorithm: Hey, leave the poor bastard alone!\n",
      "After the algorithm: Hey, leave the poor alone!\n",
      "21. Before the algorithm: It told you this was a waste of my fucking time.\n",
      "After the algorithm: It told you this was a waste of my time.\n",
      "24. Before the algorithm: 'Shut up, you two, 'said Granny.\n",
      "After the algorithm: ' up, you two, ' said Granny.\n",
      "26. Before the algorithm: Does anal...\n",
      "After the algorithm: Does..\n",
      "30. Before the algorithm: What the hell is going on?\n",
      "After the algorithm: What the is going on?\n",
      "32. Before the algorithm: I don't have to do shit.\n",
      "After the algorithm: I don't have to do\n",
      "33. Before the algorithm: God damn, this is gonna be a long night.\n",
      "After the algorithm: God this is gonna be a long night.\n",
      "37. Before the algorithm: where the hell did you get that?\n",
      "After the algorithm: where the did you get that?\n",
      "39. Before the algorithm: what the fuck was that all about?\n",
      "After the algorithm: what the was that all about?\n",
      "40. Before the algorithm: Fuck! Get out of the fucking way!\n",
      "After the algorithm: Get out of the way!\n",
      "41. Before the algorithm: Trying to kill Ethan.\n",
      "After the algorithm: Trying to Ethan.\n",
      "42. Before the algorithm: \"Thanks, ass hole,\" Case said.\n",
      "After the algorithm: \" Thanks, hole, \" Case said.\n",
      "44. Before the algorithm: Really fucking annoying.\n",
      "After the algorithm: Really annoying.\n",
      "Number of identical sentences: 18\n"
     ]
    }
   ],
   "source": [
    "basic_comparison(X[:50], output_2[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e911ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Before the algorithm: I have orders to kill her.\n",
      "After the algorithm: I have orders to her.\n",
      "26. Before the algorithm: Does anal...\n",
      "After the algorithm: Does..\n",
      "32. Before the algorithm: I don't have to do shit.\n",
      "After the algorithm: I don't have to do\n",
      "40. Before the algorithm: Fuck! Get out of the fucking way!\n",
      "After the algorithm: Get out of the way!\n",
      "41. Before the algorithm: Trying to kill Ethan.\n",
      "After the algorithm: Trying to Ethan.\n",
      "42. Before the algorithm: \"Thanks, ass hole,\" Case said.\n",
      "After the algorithm: \" Thanks, hole, \" Case said.\n",
      "44. Before the algorithm: Really fucking annoying.\n",
      "After the algorithm: Really annoying.\n",
      "Number of identical sentences: 22\n"
     ]
    }
   ],
   "source": [
    "comparison_with_cosine(X[:50], output_2[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884eda1",
   "metadata": {},
   "source": [
    "##### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b874b",
   "metadata": {},
   "source": [
    "In this case, more sentences are changed, so the algorithm depends on the list of toxic words. So this file is better to use for further work.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4435add0",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec120a9",
   "metadata": {},
   "source": [
    "As previously mentioned, a significant number of sentences remain unaltered, largely owing to the context in which they are framed. When we look at the comparison made using the cosine analogy, we observe minimal alterations to these sentences. However, there exist other challenges. Notably, when we remove offensive or toxic words from a sentence, there is a risk of losing its intended meaning or rendering the sentence incorrect. To address this issue effectively, it is advisable not merely to eliminate words but also to substitute them with more benign or less harmful alternatives, preserving the intended meaning and ensuring the sentences remain accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
