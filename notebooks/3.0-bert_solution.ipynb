{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8816ca89",
   "metadata": {},
   "source": [
    "## BERT solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575df77",
   "metadata": {},
   "source": [
    "This notebook provides a solution using a pre-trained BERT model that substitutes words in a sentence depending on the context. Also the model uses a list of toxic words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9019ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2256df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963ad45",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6315574",
   "metadata": {},
   "source": [
    "#### 1. Load the test dataset as this is a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5efdaac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('../data/interim/test.csv')\n",
    "\n",
    "X = test_df['source'].to_list()\n",
    "y = test_df['target'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707989f2",
   "metadata": {},
   "source": [
    "#### 2. Upload only the list of toxic words found on the Internet, because in the base solution the algorithm worked better with just this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7601ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_words = []\n",
    "\n",
    "with open('../data/external/profanity_words_en.txt', \"r\") as f:\n",
    "    for word in f.readlines():\n",
    "        toxic_words.append(word[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8274c",
   "metadata": {},
   "source": [
    "## Initialize the BERT tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34850f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9efbb",
   "metadata": {},
   "source": [
    "## BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcad2c",
   "metadata": {},
   "source": [
    "#### A function that replaces toxic words with \"[MASK]\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46629d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask(sentence, toxic_words):\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    tokenizer = RegexpTokenizer(r\"\\b\\w+\\b|[.,!?'\\\"]\")\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    mask_sentence = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        \n",
    "        if token.lower() in toxic_words:\n",
    "            # If it's toxic, replace it with [MASK]\n",
    "            mask_sentence.append('[MASK]')\n",
    "        else:\n",
    "            # Otherwise, keep the token as is\n",
    "            mask_sentence.append(token)\n",
    "            \n",
    "    result_sentence = ' '.join(mask_sentence)\n",
    "\n",
    "    # Correctly handle contractions like \"It's\"\n",
    "    result_sentence = re.sub(r\"(\\w+) ' (\\w+)\", r\"\\1'\\2\", result_sentence)\n",
    "\n",
    "    # Remove spaces before punctuation\n",
    "    result_sentence = re.sub(r\" ([.,!?])\", r\"\\1\", result_sentence)\n",
    "\n",
    "    return result_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc23812",
   "metadata": {},
   "source": [
    "#### A function using a pre-trained model to replace \"[MASK]\" with a matching word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc845b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detoxify_sentences(sentences, toxic_words, tokenizer):\n",
    "    \n",
    "    detoxified_sentences = []\n",
    "    \n",
    "    for i in tqdm(range(len(sentences))):\n",
    "    \n",
    "        mask_sentence = add_mask(sentences[i], toxic_words)\n",
    "\n",
    "        if '[MASK]' in mask_sentence:\n",
    "\n",
    "            # Tokenize the sentence\n",
    "            inputs = tokenizer(mask_sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            \n",
    "            # Find the positions of the [MASK] tokens in the input\n",
    "            mask_positions = torch.where(inputs.input_ids[0] == tokenizer.mask_token_id)\n",
    "\n",
    "            # Predict the words for the [MASK] token\n",
    "            with torch.no_grad():\n",
    "                predictions = model(**inputs).logits[0]\n",
    "                \n",
    "            # Initialize a list to store predicted words\n",
    "            predicted_words = []\n",
    "\n",
    "            # Extract the predicted words for each [MASK] token\n",
    "            for position in mask_positions[0]:\n",
    "                predicted_word_index = torch.argmax(predictions[position]).item()\n",
    "                predicted_word = tokenizer.convert_ids_to_tokens(predicted_word_index)\n",
    "                predicted_words.append(predicted_word)\n",
    "\n",
    "            # Replace the [MASK] tokens with the predicted words\n",
    "            for predicted_word in predicted_words:\n",
    "                mask_sentence = mask_sentence.replace(\"[MASK]\", predicted_word, 1)\n",
    "\n",
    "        detoxified_sentences.append(mask_sentence)\n",
    "        \n",
    "    return detoxified_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266069fc",
   "metadata": {},
   "source": [
    "### Functions for comparing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff7b26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_comparison(X, output):\n",
    "    same = 0\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        # Check if the output sentence differs from the original\n",
    "        if X[i] != output[i]:\n",
    "            if len(X[i]) <= 50:\n",
    "                print(f'{i + 1}. Before the algorithm: {X[i]}\\nAfter the algorithm: {output[i]}')\n",
    "        else:\n",
    "            # Count identical sentences\n",
    "            same += 1\n",
    "\n",
    "    print('Number of identical sentences:', same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97938521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similar(sentence1, sentence2):\n",
    "    \n",
    "    # Create a CountVectorizer to convert sentences into a bag of words representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    sentences = [sentence1, sentence2]\n",
    "    v = vectorizer.fit_transform(sentences)\n",
    "\n",
    "    # Calculate cosine similarity between the sentences\n",
    "    cosine_similarities = cosine_similarity(v)\n",
    "    \n",
    "    return cosine_similarities[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a6e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_with_cosine(output, y, X):\n",
    "    \n",
    "    cs = cosine_similar(y, output)\n",
    "    \n",
    "    print(f'Cosine similar: {cs}\\nPredicted: {output}\\nTarget: {y}\\nSource: {X}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f5e9d",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f3afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [06:42<00:00, 12.41it/s]\n"
     ]
    }
   ],
   "source": [
    "output = detoxify_sentences(X[:5000], toxic_words, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce186e",
   "metadata": {},
   "source": [
    "#### 1. Comparison of the predicted sentence and the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09ffd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Before the algorithm: I don't know who the fuck Wang is!\n",
      "After the algorithm: I don't know who the man guy is!\n",
      "3. Before the algorithm: Oz Veuish and Stupid.\n",
      "After the algorithm: Oz Veuish and die.\n",
      "7. Before the algorithm: let's drink to fuck.\n",
      "After the algorithm: let's drink to that.\n",
      "16. Before the algorithm: you want to molest another doctor first?\n",
      "After the algorithm: you want to see another doctor first?\n",
      "22. Before the algorithm: The bald wanker knows something.\n",
      "After the algorithm: The bald man knows something.\n",
      "28. Before the algorithm: Hey fish, you get a lot of pussy, huh?\n",
      "After the algorithm: Hey fish, you get a lot of attention, huh?\n",
      "29. Before the algorithm: Shit, I ain't built like you, John.\n",
      "After the algorithm: no, I ain't built like you, John.\n",
      "30. Before the algorithm: Mick, he's holding me hostage. Shut up and listen.\n",
      "After the algorithm: Mick, he's holding me hostage. listen up and listen.\n",
      "39. Before the algorithm: He--he is... black smoke.\n",
      "After the algorithm: He he is... black smoke.\n",
      "42. Before the algorithm: Damn,that was good.\n",
      "After the algorithm: well, that was good.\n",
      "43. Before the algorithm: Do you prefer it if I live in a shithole?\n",
      "After the algorithm: Do you prefer it if I live in a house?\n",
      "Number of identical sentences: 24\n"
     ]
    }
   ],
   "source": [
    "basic_comparison(X[:50], output[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67d049",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0faf7a",
   "metadata": {},
   "source": [
    "Comparing the predicted sentence and the source we can conclude that this model does not perform well enough as it did not change almost half of the processed sentences. Although this problem is more related to the fact that the toxic word list is not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680926c8",
   "metadata": {},
   "source": [
    "#### 2. Comparison between the predicted sentence and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a0c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similar: 0.6708203932499369\n",
      "Predicted: let's drink to that.\n",
      "Target: Let's drink to somethin' else.\n",
      "Source: let's drink to fuck.\n",
      "\n",
      "Cosine similar: 0.801783725737273\n",
      "Predicted: you want to see another doctor first?\n",
      "Target: You want to annoy another doctor first? Eventually...\n",
      "Source: you want to molest another doctor first?\n",
      "\n",
      "Cosine similar: 1.0\n",
      "Predicted: well, that was good.\n",
      "Target: well, that was good.\n",
      "Source: Damn,that was good.\n",
      "\n",
      "Cosine similar: 0.4999999999999999\n",
      "Predicted: I m a good cook.\n",
      "Target: I'm a terrible cook.\n",
      "Source: I’m a pathetic cook.\n",
      "\n",
      "Cosine similar: 0.5477225575051662\n",
      "Predicted: you hit your own head.\n",
      "Target: You banged your head real bad.\n",
      "Source: you hit your fucking head.\n",
      "\n",
      "Cosine similar: 0.8117077033708014\n",
      "Predicted: first my potatoes, then my tomatoes, then my salad, and now my salad and now the green beans.\n",
      "Target: First my potatoes, then my tomatoes, then my lettuces, now my goddam beans.\n",
      "Source: first my potatoes, then my tomatoes, then my salad, and now my salad and now the damn beans.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [6, 15, 41, 65, 78, 106]:\n",
    "\n",
    "    comparison_with_cosine(output[i], y[i], X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f7824",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f971b",
   "metadata": {},
   "source": [
    "Comparing the predicted sentence with the target sentence, we can conclude that in some cases the algorithm performs well (high similarity with the target). But unfortunately, since the model does not know which word was behind the mask before, it sometimes changes the meaning of collocations or sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9634b",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba706a",
   "metadata": {},
   "source": [
    "In general, we can say that the pre-trained BERT model performs well in this task. Compared to the baseline solution, the model looks at the context of the sentence and substitutes suitable words. Unfortunately, the model does not perform well enough due to the fact that it depends on a list of toxic words, so it is worth either finding a more appropriate list of words or finding a list-independent solution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
